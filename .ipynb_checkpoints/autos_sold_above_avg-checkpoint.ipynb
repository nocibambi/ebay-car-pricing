{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer, MinMaxScaler, OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from imblearn.pipeline import Pipeline as imbPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier, LocalOutlierFactor\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, IsolationForest, \\\n",
    "    GradientBoostingClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis, LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, \\\n",
    "    cross_validate, cross_val_predict, GridSearchCV, ParameterGrid, RepeatedStratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest, chi2, RFE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, auc, roc_curve, roc_auc_score as auc_score, confusion_matrix, \\\n",
    "    classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"autos_training_final.csv\", sep=\"|\")\n",
    "samp = train.sample(frac=0.25).copy() # For performance reasons we might want to try out the code only on a sample\n",
    "\n",
    "test = pd.read_csv(\"autos_testing_final.csv\", sep=\"|\")\n",
    "sample_submission = pd.read_csv(\"autos_submission.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining column groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Special columns\n",
    "spec_cols = ['id', 'label', 'dateCrawled']\n",
    "\n",
    "# Redundant columns\n",
    "# These columns have either the same value across the dataset or contain only very little variation\n",
    "redundant_cols = ['seller', 'offerType', 'nrOfPictures'] \n",
    "\n",
    "# relevant columns with DateTime type\n",
    "date_cols = ['dateCreated', 'lastSeen']\n",
    "\n",
    "# Numerical columns\n",
    "num_cols = train.loc[:,~train.columns.isin(spec_cols + redundant_cols + date_cols)] \\\n",
    "                .select_dtypes(include=[int, float]) \\\n",
    "                .columns\n",
    "\n",
    "# Categorical columns\n",
    "cat_cols = train.select_dtypes(include=object).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attribute specific missing value codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following columns have their own 'missing values' codes\n",
    "col_nanval = [['yearOfRegistration', 1000],\n",
    "              ['powerPS', 0],\n",
    "              ['monthOfRegistration', 0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling native missing data codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rep_nanvals(data, collist, inplace=False):\n",
    "    \"\"\"Replaces missing value codes with a random value from among the rest of values in the column.\n",
    "    Takes the data and a list of column-missing code pairs.\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    print(\"\\nReplacing data-specific missing codes...\")  \n",
    "    \n",
    "    for col_nan in collist:\n",
    "        col = data.loc[:, col_nan[0]]\n",
    "        nanval = col_nan[1]\n",
    "        col.replace(to_replace=nanval,\n",
    "                    value=np.random.choice(col[col != nanval]),\n",
    "                    inplace=inplace)\n",
    "    \n",
    "    end = time.time()\n",
    "    print(\"Duration:{}\".format(end - start))  \n",
    "    \n",
    "# Possible development: use sklearn's Impute() instead, predict missing values based on already existing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rep_nas(data, inplace=False):\n",
    "    \"\"\"Replaces NaN values with a random value from among the rest of values in the column.\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    print(\"\\nReplacing NaN values...\")    \n",
    "    \n",
    "    for col in data.isna().mean()[data.isna().any() == True].index:\n",
    "        dcol = data.loc[:,col]\n",
    "        dcol.fillna(value=np.random.choice(dcol[dcol.isna() == False]),\n",
    "                               inplace=inplace)\n",
    "\n",
    "    end = time.time()\n",
    "    print(\"Duration:{}\".format(end - start))        \n",
    "\n",
    "# Possible development: use sklearn's Impute() instead, predict missing values based on already existing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging the registration date columns into a single registration date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yr_mth(data, yrcol, mtcol, inplace=False):\n",
    "    \"\"\"Takes the data, and the year and month columns and merge them into a single \"yr_mth\" column in the\n",
    "    YYYY.MM format.\n",
    "    \"\"\"\n",
    "    data.loc[:,'yr_mth'] = data.loc[:,[yrcol, mtcol]] \\\n",
    "        .apply(lambda x: str(x[0])[:4] + \".\" + str(x[1])[:-2], axis=1)\n",
    "    data.drop(columns=[yrcol, mtcol], inplace=inplace)\n",
    "    \n",
    "    #print(data.yr_mth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the datatype columns into separate date/time columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_datetype(data, datcols, inplace=False):\n",
    "    \"\"\"Splitting datetype columns into separated year, month and day columns\n",
    "    Takes the dataframe and the list of column names.\n",
    "    Returns the dataframes with the new and without the old columns.\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    print(\"\\nSplitting date columns...\")\n",
    "\n",
    "    for col in datcols:\n",
    "        datcol = data.loc[:,col]\n",
    "        data.loc[:,col + \"_yr\"] = datcol.apply(lambda x: int(str(x)[0:4]))\n",
    "        data.loc[:,col + \"_mt\"] = datcol.apply(lambda x: int(str(x)[5:7]))\n",
    "        data.loc[:,col + \"_dy\"] = datcol.apply(lambda x: int(str(x)[8:10]))\n",
    "        #data.loc[:,col + \"_hr\"] = datcol.apply(lambda x: int(str(x)[11:13]))\n",
    "\n",
    "    def calc_date(row):\n",
    "        duration = date(row.lastSeen_yr,\n",
    "                        row.lastSeen_mt,\n",
    "                        row.lastSeen_dy) - date(row.dateCreated_yr,\n",
    "                                                row.dateCreated_mt,\n",
    "                                                row.dateCreated_dy)\n",
    "        return duration.days\n",
    "\n",
    "    dur = data.apply(lambda x: calc_date(x), axis=1)\n",
    "    data.loc[:,'visiblePeriod'] = dur\n",
    "    data.drop(columns=datcols, inplace=inplace)\n",
    "\n",
    "    end = time.time()\n",
    "    print(\"Duration:{}\".format(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming categorical values into dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_dummies(data):\n",
    "    \"\"\"Transforms all categorical attributes into dummy attributes.\n",
    "    Takes a DataFrame.\n",
    "    \n",
    "    Returns the original DataFrame's without its categorical ('object' datatype) attributes.\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    print(\"\\nCreating dummy variables...\")\n",
    "    dum_cols = data.loc[:,cat_cols] \\\n",
    "                   .columns.difference(spec_cols\n",
    "                                       + redundant_cols\n",
    "                                       + date_cols).drop('name')\n",
    "\n",
    "    #print(\"data.columns:{}\".format(data.columns))\n",
    "    #print(\"dum_cols:{}\".format(dum_cols))\n",
    "    #print(\"Columns transformed to dummies: {}\".format(dum_cols))\n",
    "\n",
    "    dummies = pd.get_dummies(data.loc[:,dum_cols])\n",
    "    #print(\"New dummy columns: {}\".format(dummies.columns))\n",
    "    w_dummies = pd.concat([data, dummies], axis=1)\n",
    "    w_dummies = w_dummies.select_dtypes(exclude=[object]) \\\n",
    "                         .dropna(axis=1)\n",
    "\n",
    "    end = time.time()\n",
    "    print(\"{} seconds\".format(end - start))\n",
    "        \n",
    "    return w_dummies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_outliers(data):\n",
    "    \"\"\"Uses IsolationForest to find outliers in the data and then drops them.\n",
    "    Takes a DataFrame.\n",
    "    \n",
    "    Returns the DataFrame without the outliers.\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    print(\"\\nHandling outliers...\")\n",
    "\n",
    "    clf = IsolationForest(max_samples='auto',\n",
    "                          random_state=2425,\n",
    "                          contamination=0.01,\n",
    "                          verbose=False,\n",
    "                          n_jobs=-1)\n",
    "\n",
    "    clf.fit(data)\n",
    "    isof = clf.predict(data)\n",
    "\n",
    "    data.loc[:,'Outlier'] = pd.Series(isof)\n",
    "    outl_rows = data[data.Outlier == -1].index\n",
    "\n",
    "    data.drop(outl_rows, inplace=True)\n",
    "    data.drop(columns='Outlier', inplace=True)\n",
    "\n",
    "    end = time.time()\n",
    "    print(\"{} seconds\".format(end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling correlated attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_cors(data):\n",
    "    \"\"\"Drops correlated attributes from a DataFrame.\n",
    "    \n",
    "    Takes a DataFrame.\n",
    "    \n",
    "    Returns the DataFrame without the correlated attributes.\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    print(\"\\nChecking for attribute correlations...\")\n",
    "\n",
    "    # Solution from Chris Albon\n",
    "    corrs = data.corr().abs()\n",
    "    upper = corrs.where(np.triu(np.ones(corrs.shape), k=1).astype(np.bool))\n",
    "\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > 0.8)]\n",
    "    print(\"Correlated attributes to drop:{}\".format(to_drop))\n",
    "\n",
    "    data.drop(data.loc[:,to_drop], axis=1, inplace=True)\n",
    "\n",
    "    end = time.time()\n",
    "    print(\"{} seconds\".format(end-start))\n",
    "    \n",
    "    return to_drop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fsel(X, y, test_data, method='univarv', model=RandomForestClassifier, k=5):\n",
    "    \"\"\"Selects features from from the dataset based on various methods.\n",
    "    Parameters\n",
    "        X: DataFrame\n",
    "            The predictor attributes\n",
    "        \n",
    "        y: DataFrame or Series\n",
    "            The label attribute to predict\n",
    "        \n",
    "        test_data: DataFrame\n",
    "            The test data\n",
    "        \n",
    "        method='univar'\n",
    "            The method to identify the selected features:\n",
    "                'univar': Univariate feature selection based on chi-squared test.\n",
    "                'rfe': Recursive Feature Elimination\n",
    "                'pca': Principal Component Analysis            \n",
    "                'fimp': Feature importance\n",
    "        \n",
    "        model=RandomForestClassifier\n",
    "            Predictor model (applicable for 'rfe' and 'fimp')\n",
    "        \n",
    "        k=5\n",
    "            Depending on the chosen method:\n",
    "                'univar', 'rfe', 'fimp': The number of best features selected.\n",
    "                'pca': The number of components to create from the attributes.\n",
    "    \n",
    "    Returns\n",
    "        The transformed training (X) and test datasets (with the best attributes or with the new components).\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    print(\"\\nAutomatic feature selection...\")\n",
    "    \n",
    "    if method == 'univar':\n",
    "        fsel_mod = SelectKBest(score_func=chi2, k=k)\n",
    "        fsel_test = fsel_mod.fit(X, y)\n",
    "\n",
    "        #print(\"Feature selection test scores:{}\".format(fsel_test.scores_))\n",
    "        features = fsel_test.transform(X)\n",
    "        fnames = pd.DataFrame(data={'attribute': X.columns,\n",
    "                                    'chi2': fsel_test.scores_}) \\\n",
    "                                    .sort_values(by='chi2', ascending=False) \\\n",
    "                                    .head(k).attribute.values\n",
    "        print(\"\\nSelected Features:\\n{}\".format(fnames))\n",
    "        \n",
    "        X_train = features\n",
    "        test = fsel_test.transform(test_data)\n",
    "\n",
    "    elif method == 'rfe':\n",
    "        fsel_mod = RFE(model(verbose=1, n_jobs=-1), k)\n",
    "        fsel_test = fsel_mod.fit(X, y)\n",
    "        fnames = X.columns[fsel_test.support_]\n",
    "        print(\"Selected Features:{}\".format(fnames))\n",
    "        \n",
    "        X_train = X.loc[:,fnames].as_matrix()\n",
    "        test = fsel_test.transform(test_data)\n",
    "\n",
    "    elif method == 'pca':\n",
    "        fsel_mod = PCA(n_components=k)\n",
    "        fsel_test = fsel_mod.fit(X)\n",
    "        print(\"Explained Variance:{}\".format(fsel_test.explained_variance_ratio_))\n",
    "        #print(\"Fit components:{}\".format(fsel_test.components_))\n",
    "        \n",
    "        X_train = fsel_test.transform(X)\n",
    "        test = fsel_test.transform(test_data)\n",
    "\n",
    "    elif method == 'fimp':\n",
    "        fsel_mod = model()\n",
    "        fsel_test = fsel_mod.fit(X, y)\n",
    "        fnames = pd.DataFrame(data={'attribute': X.columns,\n",
    "                                    'fimp': fsel_test.feature_importances_}) \\\n",
    "                                    .sort_values(by='fimp', ascending=False) \\\n",
    "                                    .head(k).attribute.values\n",
    "        print(\"Selected Features:{}\".format(fnames))\n",
    "        \n",
    "        X_train = X.loc[:,fnames].as_matrix()\n",
    "        test = test_data.loc[:,fnames].as_matrix()\n",
    "\n",
    "    else:\n",
    "        print(\"The {} method does not exist!\".format(method))\n",
    "    \n",
    "    end = time.time()\n",
    "    print(\"{} seconds\".format(end - start))\n",
    "    \n",
    "    return X_train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(train, test):\n",
    "    \"\"\"\\nStandardize the traning and test datasets.\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    print(\"\\nStandardization...\")\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(train)\n",
    "\n",
    "    train = scaler.transform(train)\n",
    "    test = scaler.transform(test)\n",
    "\n",
    "    end = time.time()\n",
    "    print(\"{} seconds\".format(end - start))\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(train, test):\n",
    "    \"\"\"Normalize the training and test datasets.\"\"\"\n",
    "    start = time.time()\n",
    "    print(\"\\nNormalization...\")\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(train)\n",
    "\n",
    "    train = scaler.transform(train)\n",
    "    test = scaler.transform(test)\n",
    "\n",
    "    print(\"{} seconds\".format(time.time() - start))\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The preprocessing function tying all the above together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(train, test,\n",
    "               dropcors=True,\n",
    "               outl_drop=True,\n",
    "               repnas=False,\n",
    "               repnanvals=True,\n",
    "               #oneregdate=False,\n",
    "               usedatecols=True,\n",
    "               usecats=True,\n",
    "               featsel=False,\n",
    "               stand=True,\n",
    "               norm=False):\n",
    "    \"\"\"Runs preprocessing steps on both the train and test data.\n",
    "    Takes the train and test data as DataFrames and the following parameters:\n",
    "    \n",
    "        dropcors=True,\n",
    "            Drop correlated attributes.\n",
    "\n",
    "        outl_drop=True,\n",
    "            Drop outliers.\n",
    "\n",
    "        repnas=False,\n",
    "            Replace missing values of an attribute with a random value from the same column.\n",
    "\n",
    "        repnanvals=True,\n",
    "            Replace missing value codes of an attribute with a random value from the same column.\n",
    "\n",
    "        #oneregdate=False,\n",
    "        #    Merges registration date columns into a single attributes.\n",
    "\n",
    "        usedatecols=True,\n",
    "            Split DateTime columns into separate year and month attributes. If \"False\", drops them.\n",
    "\n",
    "        usecats=True\n",
    "            Transform categorical values into dummy attributes. If \"False\", drops them.\n",
    "        \n",
    "        featsel=False\n",
    "            The automatic feature selection method:\n",
    "            \n",
    "            'univar': Univariate feature selection based on chi-squared test.\n",
    "            'rfe': Recursive Feature Elimination\n",
    "            'pca': Principal Component Analysis\n",
    "            'fimp': Feature importance\n",
    "        \n",
    "        stand=True\n",
    "            Strandardize the train and test datasets.\n",
    "        \n",
    "        norm=False\n",
    "            Normalize the train and test datasets.\n",
    "\n",
    "    Returns the following items:\n",
    "    X_train\n",
    "        The preprocessed training dataset\n",
    "\n",
    "    y_train\n",
    "        The target data for X_train\n",
    "\n",
    "    X_test\n",
    "        The preprocessed test dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    cord_cols = []\n",
    "    datasets = ['tr', 'te']\n",
    "    training_rows = []\n",
    "\n",
    "    X_train = np.array([])\n",
    "    X_test = np.array([])\n",
    "    \n",
    "    y_train =  train.loc[:,['label']].copy()\n",
    "    train = train.loc[:,train.columns.difference(['id', 'label'])]\n",
    "    test = test.loc[:,test.columns.difference(['id'])]    \n",
    "    \n",
    "    \n",
    "    for data in (train, test):\n",
    "        #print(\"\\nOriginal:{}\".format(data.shape))\n",
    "        #print(\"columns:\\n{}\\n\".format(data.columns))\n",
    "\n",
    "        if repnanvals == True: # Replacing data-specific missing codes\n",
    "            rep_nanvals(data, col_nanval, inplace=True)\n",
    "            #print(\"nanvals:{}\".format(data.shape))\n",
    "            #print(\"columns:\\n{}\\n\".format(data.columns))\n",
    "\n",
    "        if repnas == True: # Replacing NaN values\n",
    "            rep_nas(data, inplace=True)\n",
    "            #print(\"repnas:{}\".format(data.shape))\n",
    "            #print(\"columns:\\n{}\\n\".format(data.columns))\n",
    "\n",
    "        #if oneregdate == True: # Merging the registration date attributes into a single one\n",
    "        #    yr_mth(data, 'yearOfRegistration', 'monthOfRegistration', inplace=True)\n",
    "        #    #print(\"yr_mth:{}\".format(data.shape))\n",
    "        #    #print(\"columns:\\n{}\\n\".format(data.columns))\n",
    "\n",
    "        if usedatecols == True: # Splitting up the attributes with DateTime data type\n",
    "            split_datetype(data, date_cols, inplace=True)\n",
    "            #print(\"split_datetype:{}\".format(data.shape))\n",
    "            #print(\"columns:\\n{}\\n\".format(data.columns))\n",
    "            #print(data.dtypes)\n",
    "\n",
    "        if usecats == True: # Using category attributes\n",
    "            data = cat_dummies(data)\n",
    "            #print(\"cat_dummies:{}\".format(data.shape))\n",
    "            #print(\"columns:\\n{}\\n\".format(data.columns))\n",
    "        else:\n",
    "            num_cols = data.select_dtypes(include=np.number).columns\n",
    "            data = data.loc[:,num_cols]\n",
    "\n",
    "        if datasets.pop(0) == 'tr': # Steps for the training dataset\n",
    "            if outl_drop == True:\n",
    "                drop_outliers(data)\n",
    "                #print(\"drop_outliers:{}\".format(data.shape))\n",
    "\n",
    "            if dropcors == True:\n",
    "                cord_cols = drop_cors(data)\n",
    "                #print(\"drop_cors:{}\".format(data.shape))\n",
    "\n",
    "            X_train = data\n",
    "            train_idx = X_train.index\n",
    "            #print(\"X_train columns:{}\".format(data.columns))\n",
    "            \n",
    "        else: # Steps for the test dataset\n",
    "            #if dropcors == True:\n",
    "            #    data.drop(data.loc[:,cord_cols], axis=1, inplace=True)\n",
    "            \n",
    "            #print(\"drop_cors:{}\".format(data.shape))\n",
    "            #print(\"X_test columns:{}\".format(data.columns))\n",
    "\n",
    "            X_test = data\n",
    "\n",
    "    # Dropping attributes from the train dataset which are not in the training data set\n",
    "    X_train.drop(columns=X_train.columns[X_train.columns.isin(X_test.columns) == False], inplace=True)\n",
    "    # X_test.drop(columns=X_test.columns[X_test.columns.isin(X_train.columns) == False], inplace=True)\n",
    "\n",
    "    print(\"X_train.shape:{}\".format(X_train.shape))\n",
    "    print(\"X_test.shape:{}\".format(X_test.shape))\n",
    "    \n",
    "    \n",
    "    # Defining the training targets for the existing rows\n",
    "    y_train = y_train.loc[train_idx, :].as_matrix().ravel()\n",
    "    \n",
    "    ## Feature selection\n",
    "    if featsel in ('univar', 'rfe', 'pca', 'fimp'):\n",
    "        X_train, X_test = fsel(X_train,\n",
    "                               y_train,\n",
    "                               test_data=X_test,\n",
    "                               method='fimp',\n",
    "                               model=RandomForestClassifier,\n",
    "                               k=90)\n",
    "\n",
    "    ## Standardization\n",
    "    if stand == True:\n",
    "        X_train, X_test = standardize(X_train, X_test)\n",
    "\n",
    "    ## Normalization\n",
    "    if norm == True:\n",
    "        X_train, X_test = nstandormalize(X_train, X_test)\n",
    "    \n",
    "    return X_train, y_train, X_test\n",
    "    \n",
    "    # Uses or results:\n",
    "    # y_train = train.loc[train_idx, 'label'].copy()\n",
    "    # results = eval_models(models, X_train, y_train)\n",
    "    # rf_gridCV_2 = param_search(X_train, y_train, RandomForestClassifier, rf_params)\n",
    "    # res = rep_cv(X_train, y_train, rf_gridCV_2.best_estimator_)\n",
    "    # get_1confs(X_train, y_train, X_test, rf_gridCV_2.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "## Models to try\n",
    "A list of models (sometimes with additional parameters) which the `eval_models` function test on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\"RandomForestClassifier\": RandomForestClassifier(max_features=0.25, criterion=\"entropy\"), # n_estimators=100\n",
    "          \"Gradient Boosting Classifier\": GradientBoostingClassifier(max_features='log2', n_estimators=500),\n",
    "          \"AdaBoost Classifier\": AdaBoostClassifier(),\n",
    "          \"LinearDiscriminantAnalysis\": LinearDiscriminantAnalysis(),\n",
    "          \"LogisticRegression\": LogisticRegression(C=1.5, penalty='l1'),\n",
    "          \"GaussianNB\": GaussianNB(),\n",
    "          \"Decision Tree Cl - Gini\": DecisionTreeClassifier(),\n",
    "          \"Extra Tree Classifier\": ExtraTreeClassifier(criterion='entropy', max_features='log2'),\n",
    "          \"MLPClassifier\": MLPClassifier(),\n",
    "          \"K-NN_3 Classifier \": KNeighborsClassifier(3),\n",
    "          \"QuadraticDiscriminantAnalysis\": QuadraticDiscriminantAnalysis(), # very bad performance\n",
    "          \"Linear SVC\": LinearSVC(),\n",
    "          }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execution\n",
    "## Preprocessing and train/test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we process the sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting date columns...\n",
      "Duration:3.6285135746002197\n",
      "\n",
      "Creating dummy variables...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andras/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  if __name__ == '__main__':\n",
      "/home/andras/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py:1367: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Handling outliers...\n",
      "22.927002668380737 seconds\n",
      "\n",
      "Checking for attribute correlations...\n",
      "Correlated attributes to drop:['lastSeen_dy', 'gearbox_manuell', 'model_601', 'model_cooper', 'model_cuore', 'model_fortwo', 'model_niva', 'model_ypsilon']\n",
      "Splitting date columns...\n",
      "Duration:15.81003737449646\n",
      "\n",
      "Creating dummy variables...\n",
      "X_train.shape:(24996, 294)\n",
      "X_test.shape:(107208, 306)\n",
      "\n",
      "Automatic feature selection...\n",
      "Selected Features:['postalCode' 'powerPS' 'yearOfRegistration' 'visiblePeriod'\n",
      " 'dateCreated_dy' 'monthOfRegistration' 'kilometer'\n",
      " 'notRepairedDamage_nein' 'notRepairedDamage_ja' 'lastSeen_mt'\n",
      " 'gearbox_automatik' 'vehicleType_cabrio' 'fuelType_benzin'\n",
      " 'vehicleType_limousine' 'fuelType_diesel' 'dateCreated_mt'\n",
      " 'vehicleType_kombi' 'vehicleType_kleinwagen' 'brand_volkswagen'\n",
      " 'model_andere' 'brand_bmw' 'brand_ford' 'brand_opel' 'brand_audi'\n",
      " 'vehicleType_coupe' 'model_golf' 'brand_mercedes_benz' 'vehicleType_bus'\n",
      " 'brand_renault' 'model_3er' 'brand_peugeot' 'vehicleType_suv'\n",
      " 'brand_sonstige_autos' 'model_corsa' 'model_a4' 'model_c_klasse'\n",
      " 'model_astra' 'fuelType_lpg' 'model_passat' 'brand_seat' 'model_e_klasse'\n",
      " 'model_a3' 'brand_fiat' 'model_focus' 'model_polo' 'brand_citroen'\n",
      " 'brand_nissan' 'brand_mazda' 'brand_toyota' 'model_5er' 'model_fiesta'\n",
      " 'brand_smart' 'model_2_reihe' 'model_vectra' 'brand_mini' 'brand_skoda'\n",
      " 'brand_hyundai' 'model_a6' 'brand_mitsubishi' 'model_transporter'\n",
      " 'vehicleType_andere' 'brand_volvo' 'model_twingo' 'model_lupo'\n",
      " 'model_a_klasse' 'model_1er' 'brand_kia' 'model_3_reihe' 'brand_honda'\n",
      " 'model_ka' 'model_clio' 'model_mondeo' 'model_punto' 'model_x_reihe'\n",
      " 'model_zafira' 'brand_porsche' 'model_micra' 'brand_suzuki'\n",
      " 'model_touran' 'model_megane' 'model_caddy' 'model_ibiza' 'model_1_reihe'\n",
      " 'model_omega' 'model_sharan' 'brand_alfa_romeo' 'brand_chevrolet'\n",
      " 'model_80' 'model_galaxy' 'model_i_reihe']\n",
      "\n",
      "Standardization...\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test = preprocess(samp, test,\n",
    "                                      dropcors=True,\n",
    "                                      outl_drop=True,\n",
    "                                      repnas=False,\n",
    "                                      repnanvals=True,\n",
    "                                      #oneregdate=False,\n",
    "                                      usedatecols=True,\n",
    "                                      usecats=True,\n",
    "                                      featsel='fimp',\n",
    "                                      stand=True,\n",
    "                                      norm=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the sample we evaluate the models. This is for taking into account the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_models(models, X, y):\n",
    "    \"\"\"Evaluates selected model's prediction power on the cross-validated training datasets.\n",
    "    Takes\n",
    "        models: Dictionary of \"model_name\": model() pairs.\n",
    "        X: predictor attributes\n",
    "        y: target attribute\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for model in models:\n",
    "        #print(\"Running {}...\".format(model))\n",
    "        #start = time.time()\n",
    "\n",
    "        result = []\n",
    "        result.append(model)\n",
    "\n",
    "        model_score = cross_validate(models[model],\n",
    "                                    X,\n",
    "                                    y,\n",
    "                                    scoring=['accuracy', # Evaluation metrics\n",
    "                                             'f1_micro',\n",
    "                                             'f1_macro',\n",
    "                                             'roc_auc'],\n",
    "                                    cv=kfold, # Cross-validation method\n",
    "                                    n_jobs=-1,\n",
    "                                    verbose=0,\n",
    "                                    return_train_score=False)\n",
    "\n",
    "        acc_mean = model_score['test_accuracy'].mean()\n",
    "        acc_std = model_score['test_accuracy'].std()\n",
    "        auc_mean = model_score['test_roc_auc'].mean()\n",
    "        auc_std = model_score['test_roc_auc'].std()\n",
    "\n",
    "        print(\"\\n{}:\\n\\tAccuracy: {} ({})\".format(model, \\\n",
    "                                                  acc_mean, \\\n",
    "                                                  auc_std))\n",
    "        print(\"\\tROC AUC: {} ({})\".format(auc_mean, auc_std))\n",
    "\n",
    "        #if model != \"Gradient Boosting Classifier\":\n",
    "        f1_micro_mean = model_score['test_f1_micro'].mean()\n",
    "        f1_micro_std = model_score['test_f1_micro'].std()\n",
    "        f1_macro_mean = model_score['test_f1_macro'].mean()\n",
    "        f1_macro_std = model_score['test_f1_macro'].std()\n",
    "        print(\"\\tF1 micro: {} ({})\".format(f1_micro_mean, f1_micro_std))\n",
    "        print(\"\\tF1 macro: {} ({})\".format(f1_macro_mean, f1_macro_std))\n",
    "\n",
    "        #result = result + [acc_mean, acc_std, auc_mean, auc_std]\n",
    "\n",
    "        dur = model_score['fit_time'].sum() + model_score['score_time'].sum()\n",
    "\n",
    "        print(\"\\tduration:{}\\n\".format(dur))\n",
    "        #result.append(dur)\n",
    "\n",
    "        #results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "seed:310\n"
     ]
    }
   ],
   "source": [
    "seed = np.random.randint(1000)\n",
    "print(\"\\nseed:{}\".format(seed))\n",
    "kfold = KFold(n_splits=5, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomForestClassifier:\n",
      "\tAccuracy: 0.6856297007521204 (0.004249796075488347)\n",
      "\tROC AUC: 0.7286371486206487 (0.004249796075488347)\n",
      "\tF1 micro: 0.6856297007521204 (0.004111521499656236)\n",
      "\tF1 macro: 0.6574699153134965 (0.004566565633545603)\n",
      "\tduration:3.1786439418792725\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    2.2s finished\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   17.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gradient Boosting Classifier:\n",
      "\tAccuracy: 0.7147143542966875 (0.001610212775274088)\n",
      "\tROC AUC: 0.7761829973963522 (0.001610212775274088)\n",
      "\tF1 micro: 0.7147143542966875 (0.001619147571199231)\n",
      "\tF1 macro: 0.6952117884733591 (0.0024308882810181727)\n",
      "\tduration:28.402589797973633\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    5.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AdaBoost Classifier:\n",
      "\tAccuracy: 0.7010321651464234 (0.0015044667359557621)\n",
      "\tROC AUC: 0.757816696602335 (0.0015044667359557621)\n",
      "\tF1 micro: 0.7010321651464234 (0.004049944226226217)\n",
      "\tF1 macro: 0.6819845814725828 (0.004971493816638616)\n",
      "\tduration:9.183548927307129\n",
      "\n",
      "\n",
      "LinearDiscriminantAnalysis:\n",
      "\tAccuracy: 0.6733877420387261 (0.005540931877173369)\n",
      "\tROC AUC: 0.7223927549903518 (0.005540931877173369)\n",
      "\tF1 micro: 0.6733877420387261 (0.005116754567741161)\n",
      "\tF1 macro: 0.6478530512414925 (0.005484193590890725)\n",
      "\tduration:3.037848949432373\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    1.8s finished\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    5.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LogisticRegression:\n",
      "\tAccuracy: 0.6773483757401184 (0.01124759941527442)\n",
      "\tROC AUC: 0.727920566407077 (0.01124759941527442)\n",
      "\tF1 micro: 0.6773483757401184 (0.00996199551761208)\n",
      "\tF1 macro: 0.6534886966353718 (0.010688878255382681)\n",
      "\tduration:9.01083517074585\n",
      "\n",
      "\n",
      "GaussianNB:\n",
      "\tAccuracy: 0.6056168987037925 (0.005210095784422305)\n",
      "\tROC AUC: 0.6331108493988093 (0.005210095784422305)\n",
      "\tF1 micro: 0.6056168987037925 (0.0049900668941583225)\n",
      "\tF1 macro: 0.5887725664736497 (0.0024190664942228056)\n",
      "\tduration:1.372654914855957\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    1.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decision Tree Cl - Gini:\n",
      "\tAccuracy: 0.6267802848455752 (0.003769548032742186)\n",
      "\tROC AUC: 0.6145903197092499 (0.003769548032742186)\n",
      "\tF1 micro: 0.6267802848455752 (0.0037780109994648625)\n",
      "\tF1 macro: 0.6143880461854277 (0.003559234627922317)\n",
      "\tduration:1.6033809185028076\n",
      "\n",
      "\n",
      "Extra Tree Classifier:\n",
      "\tAccuracy: 0.6100576092174749 (0.005715365694439264)\n",
      "\tROC AUC: 0.5963861611042985 (0.005715365694439264)\n",
      "\tF1 micro: 0.6100576092174749 (0.006371953510022258)\n",
      "\tF1 macro: 0.5964462302429795 (0.005985900216811845)\n",
      "\tduration:0.6123700141906738\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MLPClassifier:\n",
      "\tAccuracy: 0.68995039206273 (0.0031715820261159666)\n",
      "\tROC AUC: 0.7451472344995346 (0.0031715820261159666)\n",
      "\tF1 micro: 0.68995039206273 (0.006041893784174415)\n",
      "\tF1 macro: 0.6775811918203951 (0.0045967594727322775)\n",
      "\tduration:102.97607207298279\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   59.3s finished\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:  3.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "K-NN_3 Classifier :\n",
      "\tAccuracy: 0.6328612578012482 (0.00644072163867189)\n",
      "\tROC AUC: 0.6496134911614518 (0.00644072163867189)\n",
      "\tF1 micro: 0.6328612578012482 (0.00212222550966148)\n",
      "\tF1 macro: 0.6156398874071046 (0.0021307994184897507)\n",
      "\tduration:365.89313292503357\n",
      "\n",
      "\n",
      "QuadraticDiscriminantAnalysis:\n",
      "\tAccuracy: 0.6158585373659785 (0.004437295764526334)\n",
      "\tROC AUC: 0.6423000198308385 (0.004437295764526334)\n",
      "\tF1 micro: 0.6158585373659785 (0.003632880808048162)\n",
      "\tF1 macro: 0.6008291913621688 (0.0008612290707583484)\n",
      "\tduration:2.830409288406372\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:    1.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Linear SVC:\n",
      "\tAccuracy: 0.6739078252520403 (0.007538920104400315)\n",
      "\tROC AUC: 0.7246988963602883 (0.007538920104400315)\n",
      "\tF1 micro: 0.6739078252520403 (0.006402774204680316)\n",
      "\tF1 macro: 0.6485909844855919 (0.006145896872768102)\n",
      "\tduration:42.51873445510864\n",
      "\n",
      "results:None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:   26.7s finished\n"
     ]
    }
   ],
   "source": [
    "results = eval_models(models, X_train, y_train)\n",
    "print(\"results:{}\".format(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid search\n",
    "After a couple of evaluation rounds we finally choose the Random Forest Classifier. It seems that with the increase of training data it tends to give the best results.\n",
    "\n",
    "Accordingly we ran GridSearch on the whole dataset with various parameters of the Random Forest Classifier.\n",
    "\n",
    "Based on the previous runs, increasing the number of estimators creates better results but also becomes very time consuming. For the sake of demonstration I set this parameter to 200. Even with this it still takes multiple hours to run the whole search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the whole dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Splitting date columns...\n",
      "Duration:36.01661014556885\n",
      "\n",
      "Creating dummy variables...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andras/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  if __name__ == '__main__':\n",
      "/home/andras/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py:1367: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Handling outliers...\n",
      "295.395299911499 seconds\n",
      "\n",
      "Checking for attribute correlations...\n",
      "Correlated attributes to drop:['lastSeen_dy', 'gearbox_manuell', 'model_601', 'model_cooper', 'model_cuore', 'model_fortwo', 'model_niva', 'model_ypsilon']\n",
      "\n",
      "Splitting date columns...\n",
      "Duration:15.385934114456177\n",
      "\n",
      "Creating dummy variables...\n",
      "X_train.shape:(247650, 298)\n",
      "X_test.shape:(107208, 306)\n",
      "\n",
      "Automatic feature selection...\n",
      "Selected Features:['postalCode' 'powerPS' 'yearOfRegistration' 'dateCreated_dy'\n",
      " 'visiblePeriod' 'monthOfRegistration' 'kilometer'\n",
      " 'notRepairedDamage_nein' 'notRepairedDamage_ja' 'lastSeen_mt'\n",
      " 'gearbox_automatik' 'fuelType_benzin' 'vehicleType_cabrio'\n",
      " 'vehicleType_limousine' 'fuelType_diesel' 'vehicleType_kombi'\n",
      " 'vehicleType_kleinwagen' 'dateCreated_mt' 'brand_volkswagen' 'model_golf'\n",
      " 'model_andere' 'brand_mercedes_benz' 'vehicleType_coupe'\n",
      " 'vehicleType_bus' 'brand_opel' 'brand_audi' 'brand_bmw' 'brand_ford'\n",
      " 'model_3er' 'brand_renault' 'brand_sonstige_autos' 'brand_peugeot'\n",
      " 'vehicleType_suv' 'model_a4' 'model_astra' 'fuelType_lpg' 'model_passat'\n",
      " 'brand_fiat' 'brand_mazda' 'model_a3' 'brand_citroen' 'brand_seat'\n",
      " 'model_c_klasse' 'model_e_klasse' 'model_corsa' 'brand_nissan'\n",
      " 'model_focus' 'model_5er' 'model_polo' 'brand_toyota'\n",
      " 'vehicleType_andere' 'brand_smart' 'model_a_klasse' 'model_a6'\n",
      " 'model_2_reihe' 'brand_hyundai' 'brand_skoda' 'model_transporter'\n",
      " 'model_fiesta' 'model_3_reihe' 'brand_mini' 'brand_mitsubishi'\n",
      " 'model_vectra' 'model_mondeo' 'model_touran' 'model_1er' 'model_twingo'\n",
      " 'model_punto' 'brand_honda' 'brand_volvo' 'model_megane' 'brand_kia'\n",
      " 'model_lupo' 'model_clio' 'model_ibiza' 'model_caddy' 'model_ka'\n",
      " 'model_zafira' 'brand_alfa_romeo' 'brand_chevrolet' 'brand_suzuki'\n",
      " 'model_x_reihe' 'model_z_reihe' 'model_octavia' 'model_sharan'\n",
      " 'model_micra' 'model_clk' 'model_i_reihe' 'model_galaxy' 'brand_porsche']\n",
      "\n",
      "Standardization...\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test = preprocess(train, test,\n",
    "                                      dropcors=True,\n",
    "                                      outl_drop=True,\n",
    "                                      repnas=False,\n",
    "                                      repnanvals=True,\n",
    "                                      #oneregdate=False,\n",
    "                                      usedatecols=True,\n",
    "                                      usecats=True,\n",
    "                                      featsel='fimp',\n",
    "                                      stand=True,\n",
    "                                      norm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_search(train, target, model, pars):\n",
    "    \"\"\"Runs a grid search on the data.\n",
    "    Takes\n",
    "        train: The predictor attributes\n",
    "        \n",
    "        target: The target attribute\n",
    "        \n",
    "        model: the used model\n",
    "        \n",
    "        pars: The parameters on which it runs the grid search.\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "\n",
    "    print(\"Starting grid search for parameters...\")\n",
    "    grid_m = GridSearchCV(\n",
    "        estimator=model(),\n",
    "        param_grid=pars.param_grid,\n",
    "        scoring=['accuracy', # Metrics to measure\n",
    "                 'f1_micro',\n",
    "                 'f1_macro',\n",
    "                 'roc_auc'],\n",
    "        n_jobs=-1,\n",
    "        verbose=2,\n",
    "        refit='roc_auc', # The chosen 'primary' metric, which it uses to refit.\n",
    "        iid=False)\n",
    "    grid_m.fit(train, target)\n",
    "    print(grid_m.cv_results_)\n",
    "\n",
    "    return grid_m\n",
    "    print(\"Duration:{}\".format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_params = ParameterGrid({\n",
    "    #'criterion': ['gini', 'entropy'],\n",
    "    #'max_depth': [None], # , 5, 4, 3\n",
    "    'max_features': [0.35, 0.3], #'sqrt', 'log2'\n",
    "    'min_samples_split': [3, 4], #0.01\n",
    "    'n_estimators': [200], # 1000\n",
    "    # 'min_samples_leaf': [0.01],\n",
    "    #'min_weight_fraction_leaf': [0.01],\n",
    "    #'min_impurtity_decrease': [0, 0.1, 0.2, 0.3],\n",
    "    'n_jobs': [-1],\n",
    "    'random_state': [seed],\n",
    "    'verbose': [0],\n",
    "    #'class_weight': [],\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rf_gridCV_2 = param_search(X_train, y_train, RandomForestClassifier, rf_params)\n",
    "print(rf_gridCV_2.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can save the results into csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(rf_gridCV_2.cv_results_).to_csv(\"GridS_test_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeated cross validation\n",
    "We use RepeatedStratifiedKFold to try to safeguard against instroducting bias thanks to the data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rep_cv(X_train, y_train, model):\n",
    "    start = time.time()\n",
    "    print(\"Running model...\")\n",
    "    model = model\n",
    "    kfold = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=seed)\n",
    "\n",
    "    rep_cv_res = cross_validate(model,\n",
    "                                X_train,\n",
    "                                y_train,\n",
    "                                scoring=['accuracy', 'roc_auc'],\n",
    "                                cv=kfold,\n",
    "                                n_jobs=-1,\n",
    "                                verbose=2,\n",
    "                                return_train_score=False)\n",
    "\n",
    "    print(\"Test accuracy:{}\".format(rep_cv_res['test_accuracy'].mean()))\n",
    "    print(\"Test ROC AUC:{}\".format(rep_cv_res['test_roc_auc'].mean()))\n",
    "    end = time.time()\n",
    "    print(\"Duration:{}\".format(end - start))\n",
    "\n",
    "    return rep_cv_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = rep_cv(X_train, y_train, rf_gridCV_2.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can save the results of the Repeated cross validaton into csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(res).to_csv(\"rep_cv_res_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the 1 confidences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_1confs(X_train, y_train, X_test, model):\n",
    "    \"\"\"Gets the confidences of 1 values as predicted by the model on the test dataset.\n",
    "    Takes\n",
    "        X_train: The predictor attributes of the training dataset\n",
    "        y_train: The target attributes of the training dataset\n",
    "        X_test: The predictor attributes of the test dataset\n",
    "        model: the used model\n",
    "        \n",
    "    It writes the results into a csv.\n",
    "    \"\"\"\n",
    "    print(\"X_test.shape:{}\".format(X_test.shape))\n",
    "    model = model\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    confs = model.predict_proba(X_test)[:,1]\n",
    "    confs = pd.DataFrame([test.id, confs.reshape(-1,)]).transpose()\n",
    "    confs.rename(columns={\"Unnamed 0\": 'label'}, inplace=True)\n",
    "    confs.to_csv(\"late.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_1confs(X_train, y_train, X_test, rf_gridCV_2.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\a\") # Not in jupyter notebook apperently"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
